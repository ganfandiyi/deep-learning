{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionTreeClassifierWithWeight:\n",
    "    def __init__(self):\n",
    "        self.best_err = 1  # 最小的加权错误率\n",
    "        self.best_fea_id = 0  # 最优特征id\n",
    "        self.best_thres = 0  # 选定特征的最优阈值\n",
    "        self.best_op = 1  # 阈值符号，其中 1: >, 0: <\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        if sample_weight is None:\n",
    "            sample_weight = np.ones(len(X)) / len(X)\n",
    "        n = X.shape[1]\n",
    "        for i in range(n):\n",
    "            feature = X[:, i]  # 选定特征列\n",
    "            fea_unique = np.sort(np.unique(feature))  # 将所有特征值从小到大排序\n",
    "            for j in range(len(fea_unique)-1):\n",
    "                thres = (fea_unique[j] + fea_unique[j+1]) / 2  # 逐一设定可能阈值\n",
    "                for op in (0, 1):\n",
    "                    y_ = 2*(feature >= thres)-1 if op==1 else 2*(feature < thres)-1  # 判断何种符号为最优\n",
    "                    err = np.sum((y_ != y)*sample_weight)\n",
    "                    if err < self.best_err:  # 当前参数组合可以获得更低错误率，更新最优参数\n",
    "                        self.best_err = err\n",
    "                        self.best_op = op\n",
    "                        self.best_fea_id = i\n",
    "                        self.best_thres = thres\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        feature = X[:, self.best_fea_id]\n",
    "        return 2*(feature >= self.best_thres)-1 if self.best_op==1 else 2*(feature < self.best_thres)-1\n",
    "    \n",
    "    def score(self, X, y, sample_weight=None):\n",
    "        y_pre = self.predict(X)\n",
    "        if sample_weight is not None:\n",
    "            return np.sum((y_pre == y)*sample_weight)\n",
    "        return np.mean(y_pre == y)\n",
    "\n",
    "class AdaBoostClassifier_:\n",
    "    def __init__(self, n_estimators=50):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.estimators = []\n",
    "        self.alphas = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        sample_weight = np.ones(len(X)) / len(X)  # 初始化样本权重为 1/N\n",
    "        for _ in range(self.n_estimators):\n",
    "            dtc = DecisionTreeClassifierWithWeight().fit(X, y, sample_weight)  # 训练弱学习器\n",
    "            alpha = 1/2 * np.log((1-dtc.best_err)/dtc.best_err)  # 权重系数\n",
    "            y_pred = dtc.predict(X)\n",
    "            sample_weight *= np.exp(-alpha*y_pred*y)  # 更新迭代样本权重\n",
    "            sample_weight /= np.sum(sample_weight)  # 样本权重归一化\n",
    "            self.estimators.append(dtc)\n",
    "            self.alphas.append(alpha)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.empty((len(X), self.n_estimators))  # 预测结果二维数组，其中每一列代表一个弱学习器的预测结果\n",
    "        for i in range(self.n_estimators):\n",
    "            y_pred[:, i] = self.estimators[i].predict(X)\n",
    "        y_pred = y_pred * np.array(self.alphas)  # 将预测结果与训练权重乘积作为集成预测结果\n",
    "        return 2*(np.sum(y_pred, axis=1)>0)-1  # 以0为阈值，判断并映射为-1和1\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return np.mean(y_pred==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8881118881118881"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "y = 2*y-1  # 将0/1取值映射为-1/1取值\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "DT=DecisionTreeClassifierWithWeight()\n",
    "DT.fit(X_train, y_train)\n",
    "DT.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9790209790209791"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ADDC=AdaBoostClassifier_()\n",
    "ADDC.fit(X_train, y_train)\n",
    "print('Scikit 预测均方差：',ADDC.score(X_test, y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit 预测均方差： 0.972027972027972\n",
      "树的个数: 50 第一颗树： DecisionTreeClassifier(max_depth=1, random_state=402639127)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "SciADDC=AdaBoostClassifier()\n",
    "SciADDC.fit(X_train, y_train)\n",
    "print('Scikit 预测均方差：',SciADDC.score(X_test, y_test))\n",
    "print('树的个数:', len(SciADDC.estimators_),'第一颗树：',SciADDC.estimators_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT预测均方差： 0.9300699300699301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model_GBDT = GradientBoostingClassifier()\n",
    "model_GBDT.fit(X_train,y_train)\n",
    "print('GBDT预测均方差：',model_GBDT.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "deee9092494de3f243baafa6e8f13ed865fb0b4f248d8311ed438590712b6c6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
