{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import optimize\n",
    "from matplotlib.font_manager import FontProperties\n",
    "font = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\", size=14)    # 解决windows环境下画图汉字乱码问题\n",
    "\n",
    "# 加载txt和csv文件\n",
    "def loadtxtAndcsv_data(fileName,split,dataType):\n",
    "    return np.loadtxt(fileName,delimiter=split,dtype=dataType)\n",
    "\n",
    "# 归一化feature\n",
    "def featureNormaliza(X):\n",
    "    X_norm = np.array(X)            #将X转化为numpy数组对象，才可以进行矩阵的运算\n",
    "    #定义所需变量\n",
    "    mu = np.zeros((1,X.shape[1]))   \n",
    "    sigma = np.zeros((1,X.shape[1]))\n",
    "    \n",
    "    # 均值方差归一化\n",
    "    mu = np.mean(X_norm,0)          # 求每一列的平均值（0指定为列，1代表行）\n",
    "    sigma = np.std(X_norm,0)        # 求每一列的标准差\n",
    "    for i in range(X.shape[1]):     # 遍历列\n",
    "        X_norm[:,i] = (X_norm[:,i]-mu[i])/sigma[i]  # 归一化\n",
    "    \n",
    "    return X_norm,mu,sigma\n",
    "\n",
    "# S型函数    \n",
    "def sigmoid(z):\n",
    "    h = np.zeros((len(z),1))    # 初始化，与z的长度一置\n",
    "    \n",
    "    h = 1.0/(1.0+np.exp(-z))\n",
    "    return h\n",
    "\n",
    "# 计算梯度\n",
    "def gradient(initial_theta,X,y,inital_lambda):\n",
    "    m = len(y)\n",
    "    grad = np.zeros((initial_theta.shape[0]))\n",
    "    \n",
    "    h = sigmoid(np.dot(X,initial_theta))# 计算h(z)\n",
    "    theta1 = initial_theta.copy()\n",
    "    theta1[0] = 0\n",
    "\n",
    "    grad = np.dot(np.transpose(X),h-y)/m+inital_lambda/m*theta1 #正则化的梯度\n",
    "    return grad\n",
    "\n",
    "# 显示二维图形\n",
    "def plot_data(X,y):\n",
    "    pos = np.where(y==1)    #找到y==1的坐标位置\n",
    "    neg = np.where(y==0)    #找到y==0的坐标位置\n",
    "    #作图\n",
    "    plt.figure(figsize=(15,12))\n",
    "    plt.plot(X[pos,0],X[pos,1],'ro')        # red o\n",
    "    plt.plot(X[neg,0],X[neg,1],'bo')        # blue o\n",
    "    plt.title(u\"两个类别散点图\",fontproperties=font)\n",
    "    plt.show()\n",
    "\n",
    "# 代价函数\n",
    "def costFunction(initial_theta,X,y,inital_lambda):\n",
    "    m = len(y)\n",
    "    J = 0\n",
    "    \n",
    "    h = sigmoid(np.dot(X,initial_theta))    # 计算h(z)\n",
    "    theta1 = initial_theta.copy()           # 因为正则化j=1从1开始，不包含0，所以复制一份，前theta(0)值为0 \n",
    "    theta1[0] = 0   \n",
    "    \n",
    "    temp = np.dot(np.transpose(theta1),theta1)\n",
    "    J = (-np.dot(np.transpose(y),np.log(h))-np.dot(np.transpose(1-y),np.log(1-h))+temp*inital_lambda/2)/m   # 正则化的代价方程\n",
    "    return J\n",
    "\n",
    "# 映射为多项式 \n",
    "def mapFeature(X1,X2):\n",
    "    degree = 2;                     # 映射的最高次方\n",
    "    out = np.ones((X1.shape[0],1))  # 映射后的结果数组（取代X）\n",
    "    '''\n",
    "    这里以degree=2为例，映射为1,x1,x2,x1^2,x1,x2,x2^2\n",
    "    '''\n",
    "    for i in np.arange(1,degree+1): \n",
    "        for j in range(i+1):\n",
    "            temp = X1**(i-j)*(X2**j)    #矩阵直接乘相当于matlab中的点乘.*\n",
    "            out = np.hstack((out, temp.reshape(-1,1)))\n",
    "    return out\n",
    "\n",
    "#画决策边界\n",
    "def plotDecisionBoundary(theta,X,y):\n",
    "    pos = np.where(y==1)    #找到y==1的坐标位置\n",
    "    neg = np.where(y==0)    #找到y==0的坐标位置\n",
    "    #作图\n",
    "    plt.figure(figsize=(15,12))\n",
    "    plt.plot(X[pos,0],X[pos,1],'ro')        # red o\n",
    "    plt.plot(X[neg,0],X[neg,1],'bo')        # blue o\n",
    "    plt.title(u\"决策边界\",fontproperties=font)\n",
    "    \n",
    "    #u = np.linspace(30,100,100)\n",
    "    #v = np.linspace(30,100,100)\n",
    "    \n",
    "    u = np.linspace(-1,1.5,50)  #根据具体的数据，这里需要调整\n",
    "    v = np.linspace(-1,1.5,50)\n",
    "    \n",
    "    z = np.zeros((len(u),len(v)))\n",
    "    for i in range(len(u)):\n",
    "        for j in range(len(v)):\n",
    "            z[i,j] = np.dot(mapFeature(u[i].reshape(1,-1),v[j].reshape(1,-1)),theta)    # 计算对应的值，需要map\n",
    "    \n",
    "    z = np.transpose(z)\n",
    "    plt.contour(u,v,z,[0,0.01],linewidth=2.0)   # 画等高线，范围在[0,0.01]，即近似为决策边界\n",
    "    #plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def LogisticRegression_NP():\n",
    "    data = loadtxtAndcsv_data(\"data2.txt\", \",\", np.float64) \n",
    "    X = data[:,0:-1]\n",
    "    y = data[:,-1]\n",
    "    \n",
    "    plot_data(X,y)  # 作图\n",
    "    \n",
    "    X = mapFeature(X[:,0],X[:,1])           #映射为多项式\n",
    "    initial_theta = np.zeros((X.shape[1],1))#初始化theta\n",
    "    initial_lambda = 0.1                    #初始化正则化系数，一般取0.01,0.1,1.....\n",
    "    \n",
    "    J = costFunction(initial_theta,X,y,initial_lambda)  #计算一下给定初始化的theta和lambda求出的代价J\n",
    "    \n",
    "    print(J)  #输出一下计算的值，应该为0.693147\n",
    "    #result = optimize.fmin(costFunction, initial_theta, args=(X,y,initial_lambda))    #直接使用最小化的方法，效果不好\n",
    "    '''调用scipy中的优化算法fmin_bfgs（拟牛顿法Broyden-Fletcher-Goldfarb-Shanno）\n",
    "    - costFunction是自己实现的一个求代价的函数，\n",
    "    - initial_theta表示初始化的值,\n",
    "    - fprime指定costFunction的梯度\n",
    "    - args是其余测参数，以元组的形式传入，最后会将最小化costFunction的theta返回 \n",
    "    '''\n",
    "    result = optimize.fmin_bfgs(costFunction, initial_theta, fprime=gradient, args=(X,y,initial_lambda))    \n",
    "    p = predict(X, result)   #预测\n",
    "    print(u'在训练集上的准确度为%f%%'%np.mean(np.float64(p==y)*100))   # 与真实值比较，p==y返回True，转化为float   \n",
    "    \n",
    "    X = data[:,0:-1]\n",
    "    y = data[:,-1]    \n",
    "    plotDecisionBoundary(result,X,y)    #画决策边界  \n",
    "\n",
    "# 预测\n",
    "def predict(X,theta):\n",
    "    m = X.shape[0]\n",
    "    p = np.zeros((m,1))\n",
    "    p = sigmoid(np.dot(X,theta))    # 预测的结果，是个概率值\n",
    "    \n",
    "    for i in range(m):\n",
    "        if p[i] > 0.5:  #概率大于0.5预测为1，否则预测为0\n",
    "            p[i] = 1\n",
    "        else:\n",
    "            p[i] = 0\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadtxtAndcsv_data(\"data2.txt\", \",\", np.float64) \n",
    "X = data[:,0:-1]\n",
    "y = data[:,-1]\n",
    "\n",
    "plot_data(X,y)  # 作图\n",
    "\n",
    "X = mapFeature(X[:,0],X[:,1])           #映射为多项式\n",
    "initial_theta = np.zeros((X.shape[1],1))#初始化theta\n",
    "initial_lambda = 0.1                    #初始化正则化系数，一般取0.01,0.1,1.....\n",
    "\n",
    "J = costFunction(initial_theta,X,y,initial_lambda)  #计算一下给定初始化的theta和lambda求出的代价J\n",
    "\n",
    "print(J)  #输出一下计算的值，应该为0.693147\n",
    "#result = optimize.fmin(costFunction, initial_theta, args=(X,y,initial_lambda))    #直接使用最小化的方法，效果不好\n",
    "'''调用scipy中的优化算法fmin_bfgs（拟牛顿法Broyden-Fletcher-Goldfarb-Shanno）\n",
    "- costFunction是自己实现的一个求代价的函数，\n",
    "- initial_theta表示初始化的值,\n",
    "- fprime指定costFunction的梯度\n",
    "- args是其余测参数，以元组的形式传入，最后会将最小化costFunction的theta返回 \n",
    "'''\n",
    "result = optimize.fmin_bfgs(costFunction, initial_theta, fprime=gradient, args=(X,y,initial_lambda))    \n",
    "p = predict(X, result)   #预测\n",
    "print(u'在训练集上的准确度为%f%%'%np.mean(np.float64(p==y)*100))   # 与真实值比较，p==y返回True，转化为float   \n",
    "\n",
    "X = data[:,0:-1]\n",
    "y = data[:,-1]    \n",
    "plotDecisionBoundary(result,X,y)    #画决策边界  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler    #引入归一化的包\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = loadtxtAndcsv_data(\"data1.txt\", \",\", np.float64)\n",
    "X = data[:,0:-1]\n",
    "y = data[:,-1]\n",
    "\n",
    "# 划分为训练集和测试集\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "# 归一化\n",
    "scaler = StandardScaler()\n",
    "# scaler.fit(x_train)\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "# 逻辑回归\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "# 预测\n",
    "predict = model.predict(x_test)\n",
    "right = sum(predict == y_test)\n",
    "\n",
    "predict = np.hstack((predict.reshape(-1,1),y_test.reshape(-1,1)))   # 将预测值和真实值放在一块，好观察\n",
    "print(predict)\n",
    "print('测试集准确率：%f%%'%(right*100.0/predict.shape[0]))          # 计算在测试集上的准确度"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "deee9092494de3f243baafa6e8f13ed865fb0b4f248d8311ed438590712b6c6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
